---
title: 消息队列
tags: [消息队列]
categories:
- 消息队列
date: 2019-09-15 14:17:46
entitle: MQ
---

消息队列知识点总结。
<!--more-->

## 优缺点

### 优点
* 解耦
* 异步
* 削峰

### 缺点

* 系统可用性降低：当MQ出问题时，将会使系统产生问题
* 系统复杂度变高：引入消息队列同时将会引入消息丢失、重复、消息顺序不一致等问题
* 一致性问题：下游系统之间如果有协作的关系，可能会导致数据不一致

## 四种消息队列的比较

比较|ActiveMQ|RabbitMQ|RocketMQ|Kafka
-|-|-|-|-
吞吐量|万级|万级|十万级|十万级
特点|成熟稳定但存在消息丢失的问题，社区不活跃|ErLang开发性能好，延时比较低，改造难度大|吞吐量高，阿里开发，topic可以达到几百几千级，使用分布式架构|功能简单，吞吐量高，易扩展，适用于大数据的事实计算、日志采集等场景


## 如何保证消息队列的高可用性

### RabbitMQ

RabbitMQ的部署方式一共有三种：单机模式、普通集群模式、镜像集群模式。

#### 普通集群模式

在普通集群模式下，Queue的消息实体仅存在于其中一个节点，节点仅有相同的元数据（队列结构）。假设存在两个节点A、B，当消息进入A节点的Queue中后，consumer从B节点拉取时，RabbitMQ会临时在A、B间进行消息传输，把A中的消息实体取出并经过B发送给consumer。

在这种模式下，RabbitMQ节点之前存在大量的数据传输，当其中一个节点挂掉后，节点的数据将无法被消费，没有可用性的保障。

#### 镜像集群模式

在镜像集群模式下，消息实体会主动在镜像节点间同步，而不是在conumer拉取时才进行同步。不同节点间的数据完全一致，在producer写入时，消息实体将会在所有镜像节点同步。

镜像集群模式虽然在一定程度上保证了HA，但是当数据量很大时，节点之间带宽将会被同步消耗，存在问题。

### Kafka

Kafka本身是分布式架构。

* Producer：生产者，消息的发送者。
* Broker：Kafka 集群由多个 Kafka 实例（server） 组成，每个实例构成一个 broker。
* Topic：每条发送到Kafka集群的消息都有其类别，这个类别称为Topic。
* Partition：Partition是物理上的概念，每个Topic包含一个或多个Partition。出于负载均衡的考虑，同一个Topic的Partitions分布在不同的broker。为了提高高可用性，Partitions可以由Kafka机制中的replicas来设置备份的数量。
* Consumer：消费者，从 Kafka 集群的 broker 中 pull 消息、消费消息
* Consumer group：high-level consumer API 中，每个 consumer 都属于一个 consumer-group，每条消息只能被 consumer-group 中的一个 Consumer 消费，但可以被多个 consumer-group 消费。
* replicas：partition 的副本，保障 partition 的高可用。
* leader：replicas 中的一个角色， producer 和 consumer 只跟 leader 交互；
* follower：replicas 中的一个角色，从 leader 中复制数据，作为副本，一旦 leader 挂掉，会从它的 followers 中选举出一个新的 leader 继续提供服务。
* controller：Kafka 集群中的其中一个服务器，用来进行 leader election 以及 各种 failover。
* ZooKeeper：Kafka 通过 ZooKeeper 来存储集群的 meta 信息等。

## 消息重复消费问题

* 通过数据库的主键作唯一性判断
* 通过维持一个Redis set，插入数据前判断

## 消息丢失问题

### RabbitMQ

消息丢失的三个场景：
* 生产者写入RabbitMQ时，MQ自身存储出错。
* 消息还未被消费，MQ自己挂了。
* 消费者还没处理完消息，消费者挂了。

#### 生产者写入问题

该问题有两种解决方式：通过AMQP事务机制实现、Confirm模式

通过AMQP事务机制实现：
RabbitMQ中与事务机制有关的方法有三个：txSelect(), txCommit()以及txRollback(), txSelect用于将当前channel设置成transaction模式，txCommit用于提交事务，txRollback用于回滚事务，在通过txSelect开启事务之后，我们便可以发布消息给broker代理服务器了，如果txCommit提交成功了，则消息一定到达了broker了，如果在txCommit执行之前broker异常崩溃或者由于其他原因抛出异常，可以捕获异常通过txRollback回滚事务了。

但AMQP是同步机制，会使吞吐量下降，影响MQ的性能。

Confirm模式：
生产者将信道设置成confirm模式，一旦信道进入confirm模式，所有在该信道上面发布的消息都会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，broker就会发送一个确认给生产者（包含消息的唯一ID）,这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会将消息写入磁盘之后发出，broker回传给生产者的确认消息中deliver-tag域包含了确认消息的序列号，此外broker也可以设置basic.ack的multiple域，表示到这个序列号之前的所有消息都已经得到了处理。

confirm模式是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack消息，生产者应用程序同样可以在回调方法中处理该nack消息。

在channel 被设置成 confirm 模式之后，所有被 publish 的后续消息都将被 confirm（即 ack） 或者被nack一次。但是没有对消息被 confirm 的快慢做任何保证，并且同一条消息不会既被 confirm又被nack 。


#### 消息未被消费，MQ挂掉
持久化到磁盘
* 创建Queue时设置为持久化，保证RabbitMQ持久化queue元数据
* 发送消息时将deliveryMode设置为2，开启消息的持久化

设置了队列和消息的持久化之后，当broker服务重启的之后，消息依旧存在。单只设置队列持久化，重启之后消息会丢失；单只设置消息的持久化，重启之后队列消失，既而消息也丢失。单单设置消息持久化而不设置队列的持久化显得毫无意义。

### 消费者未消费完消息，消费者挂掉
关闭AutoACK机制，处理完数据后手动发送ACK。


### Kafka

#### 消费者未消费完消息
关闭自动提交offset，改为手动提交。

#### Kafka自身

1. topic设置`replication.factor`参数，每个partition必须至少有两个replica
2. Kafka服务器端设置`min.insync.replicas`大于1，即要求至少leader至少感知到有一个follower保持联系。
3. producer端设置`ack=all`，即必须写入所有的replica之后认为写入成功。
4. producer设置`retries=MAX`，即一旦写入失败，进行无限重试。

第三点和第四点同时保证了生产者不会丢失消息。

## 保证消息队列按顺序获取队列中的数据

顺序错乱的两个场景：
1. RabbitMQ，一个queue对应多个consumer
2. Kafka消费者多线程消费

### RabbitMQ
对queue进行拆分，把需要保证顺序的数据写入到一个queue中。

### Kafka

写入到统一partition的顺序性由kafka自身保证，当消费者端起多个线程消费partition中的数据时，仍存在问题。

在消费者端，可以根据数据顺序Hash到不同的内存队列中处理。每个内存队列对应一个线程处理数据。






























## 参考资料

石杉的架构笔记
[深入浅出理解Kafka 分布式消息队列](http://melanx.com/2019/01/07/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%90%86%E8%A7%A3-kafka-%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/)
[RabbitMQ之消息确认机制（事务+Confirm）](https://blog.csdn.net/u013256816/article/details/55515234)






